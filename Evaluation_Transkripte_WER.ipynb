{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Zuerst die beiden Transkripte Dateien zusammenfügen"
      ],
      "metadata": {
        "id": "y4oTgEH0oB_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mMH0FXFLIicf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive benutzen um Dateien permanent zu speichern\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/mnt/drive')\n",
        "\n",
        "base_path = \"/mnt/drive/MyDrive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaBQkEchIcgQ",
        "outputId": "8267fc1e-c106-43a5-c5d5-62f76cb14312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /mnt/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lese die erste CSV-Datei\n",
        "df1 = pd.read_csv('/mnt/drive/MyDrive/MasterArbeitDatenLokal/LokaleGruppen/alle_transkripteLokal.csv')\n",
        "\n",
        "# Lese die zweite CSV-Datei\n",
        "df2 = pd.read_csv('/mnt/drive/MyDrive/MasterArbeitDaten/alle_transkripteInfluencer.csv')\n"
      ],
      "metadata": {
        "id": "UfB8DBubokve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zusammenführen der DataFrames\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Speichern des kombinierten DataFrames in eine neue CSV-Datei\n",
        "combined_df.to_csv('/mnt/drive/MyDrive/AlleTranskripte.csv', index=False)\n"
      ],
      "metadata": {
        "id": "d4xczcNGot3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Anzahl an Transkripten pro Gruppe berechnen und dem df hinzufügen"
      ],
      "metadata": {
        "id": "0330tDHHoITI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/mnt/drive/MyDrive/AlleTranskripte.csv')\n",
        "\n",
        "# Hinzufügen der Anzahl der Transkripte pro Gruppe zum DataFrame\n",
        "df['Anzahl_Transkripte'] = df.groupby('Identifier')['Inhalt'].transform('count')\n",
        "\n",
        "# Speichern des DataFrames in eine CSV-Datei\n",
        "output_filename = '/mnt/drive/MyDrive/AlleTranskripteMitAnzahl.csv'\n",
        "df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"Der DataFrame wurde erfolgreich als {output_filename} gespeichert.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd5Q3F9AoNbG",
        "outputId": "a408f272-21d6-4917-9cd7-d1a74da0b440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Der DataFrame wurde erfolgreich als /mnt/drive/MyDrive/AlleTranskripteMitAnzahl.csv gespeichert.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Erstellen eines stratified samples"
      ],
      "metadata": {
        "id": "E8d0uU-toN2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('/mnt/drive/MyDrive/AlleTranskripteMitAnzahl.csv')\n",
        "\n",
        "# Erzeugen einer stratifizierten Stichprobe basierend auf der 'Anzahl_Transkripte' Spalte\n",
        "train, sample = train_test_split(df, test_size=0.05, stratify=df['Anzahl_Transkripte'], random_state=42)\n",
        "\n",
        "# Anzeigen der stratifizierten Stichprobe\n",
        "print(sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rihgtTivoPw-",
        "outputId": "f3b2176d-b488-4df4-f3f7-2903df77ac62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Identifier  \\\n",
            "19227  schwurbelarchiv-g6Sbm9HSmG   \n",
            "27768  schwurbelarchiv-11I2gdLfJW   \n",
            "1142   schwurbelarchiv-DIxrNAFZYl   \n",
            "23473  schwurbelarchiv-QDHQA6B3qC   \n",
            "1994   schwurbelarchiv-HJmOiP7hRs   \n",
            "...                           ...   \n",
            "14459  schwurbelarchiv-lDobCFaR2c   \n",
            "12836  schwurbelarchiv-k0eohVhfDE   \n",
            "6577   schwurbelarchiv-lNtnSXDOJk   \n",
            "24871  schwurbelarchiv-k8vmjIscYR   \n",
            "15100  schwurbelarchiv-lDobCFaR2c   \n",
            "\n",
            "                                          Dateiname  \\\n",
            "19227                       IMG_4142_transcript.txt   \n",
            "27768   video_39@06-05-2020_23-57-51_transcript.txt   \n",
            "1142       video_2020-12-23_15-54-25_transcript.txt   \n",
            "23473      video_2019-10-09_14-27-20_transcript.txt   \n",
            "1994   video_982@10-11-2020_18-18-20_transcript.txt   \n",
            "...                                             ...   \n",
            "14459                   hollnadPolit_transcript.txt   \n",
            "12836  video_123@24-11-2020_15-07-31_transcript.txt   \n",
            "6577                   Maskenpflicht_transcript.txt   \n",
            "24871  video_610@02-06-2020_11-37-16_transcript.txt   \n",
            "15100                             2G_transcript.txt   \n",
            "\n",
            "                                                  Inhalt  Anzahl_Transkripte  \n",
            "19227                             Die Kanzlerin schreit.                  84  \n",
            "27768  Mir ist der Eindämmungsverordnung des Dienst n...                 918  \n",
            "1142   Herr Reichert, dringende Redaktionssitzung. Ma...                 353  \n",
            "23473  Leute, ich lebe noch, hatte keine Verfolgungsf...                1331  \n",
            "1994   Er ist  Arizona. Look, the news organizations ...                1502  \n",
            "...                                                  ...                 ...  \n",
            "14459  In 2010 entwickelte die Rockefeller Foundation...                1640  \n",
            "12836  Wenn ich jetzt im Saarland bin, dann darf ich ...                 678  \n",
            "6577   Wissen Sie was? Ich werde Ihnen was vorlesen. ...                 152  \n",
            "24871                                                Ja!                 390  \n",
            "15100  Ich bin so abgefuckt und ich verstehe das Them...                1640  \n",
            "\n",
            "[1587 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Speichern des DataFrames in eine CSV-Datei\n",
        "output_filename = '/mnt/drive/MyDrive/AlleTranskripteSample5%.csv'\n",
        "sample.to_csv(output_filename, index=False)"
      ],
      "metadata": {
        "id": "O23eKip95IXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Berechnung der Word Error Rate"
      ],
      "metadata": {
        "id": "UmSeN4ieYPf4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2Hm1Gv-DepF",
        "outputId": "8b2d8f87-71e2-40ae-e6c5-8e28adb76fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Durchschnittliche Word Error Rate (WER) nach Filterung: 37.10%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk.metrics import edit_distance  # Falls nicht installiert, verwende: !pip install nltk\n",
        "\n",
        "# CSV-Datei laden\n",
        "df = pd.read_csv(\"/content/AlleTranskripte5%Versuch.csv\", delimiter=\";\", quotechar='\"')  # Ersetze mit dem Pfad zur CSV-Datei\n",
        "\n",
        "# Spaltennamen anpassen\n",
        "automated_column = \"Inhalt\"\n",
        "manual_column = \"Mein Transkript\"\n",
        "annotation_column = \"Anmerkung\"\n",
        "\n",
        "# Filterung der Transkripte\n",
        "df_filtered = df[(df[manual_column].notna()) &\n",
        "                 (df[manual_column].str.strip() != \"\") &  # Stellt sicher, dass das Transkript nicht leer ist\n",
        "                 (~df[annotation_column].str.contains(\"Übersetzungsfehler\", case=False, na=False))].copy()\n",
        "\n",
        "# WER-Berechnung ohne jiwer\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    ref_words = reference.split()\n",
        "    hyp_words = hypothesis.split()\n",
        "    distance = edit_distance(ref_words, hyp_words)  # Berechnung des Levenshtein-Abstands auf Wortebene\n",
        "    return distance / len(ref_words) if len(ref_words) > 0 else float('inf')  # Schutz vor Division durch Null\n",
        "\n",
        "# WER berechnen für jedes gefilterte Paar\n",
        "df_filtered['WER'] = df_filtered.apply(lambda row: calculate_wer(row[manual_column], row[automated_column]), axis=1)\n",
        "\n",
        "# Durchschnittliche WER berechnen\n",
        "average_wer = df_filtered['WER'].mean()\n",
        "\n",
        "# Ergebnis anzeigen\n",
        "print(f\"Durchschnittliche Word Error Rate (WER) nach Filterung: {average_wer:.2%}\")\n",
        "\n"
      ]
    }
  ]
}